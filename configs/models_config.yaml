# configs/models_config.yaml
# 模型库 (System Models)
models:
  # 1. 本地 VLLM 部署的模型 (使用 OpenAI 兼容接口)
  qwen3-4b-local:
    provider: "openai_compatible"
    display_name: "Qwen3-4B-Instruct (本地)"
    api_base: "http://localhost:8000/v1"
    api_key: "not-used"
    model_name: "/models/Qwen3-4B-Instruct-2507"  # 默认docker容器地址
    parameters:
      temperature: 0.7
      max_tokens: 4096

  # 2. 在线 OpenAI API 模型 (示例)
  # gpt-4o:
  #   provider: "openai_compatible"
  #   display_name: "GPT-4o (OpenAI API)"
  #   api_base: "https://api.openai.com/v1"
  #   api_key: "ENV:OPENAI_API_KEY" # 建议从环境变量读取
  #   model_name: "gpt-4o"
  #   parameters:
  #     temperature: 0.8
  #     max_tokens: 4096

# 指令库 (System Prompts)
# 在交互式聊天中通过 /role <指令名> 来使用
instructions:
  default:
    display_name: "通用助手 (Default)"
    template: "You are a helpful and friendly AI assistant. Your responses should be clear, concise, and accurate."
  
  code_expert:
    display_name: "编程专家 (Code Expert)"
    template: "You are an expert programmer with years of experience in multiple languages, especially Python. Provide clean, efficient, and well-documented code. Always explain your reasoning and offer best practices."
  
  linux_terminal:
    display_name: "Linux终端模拟器 (Linux Terminal)"
    template: "You are a Linux terminal simulator. Emulate the behavior of a bash terminal. Respond only with the standard output of the executed command. If a command is not valid, respond with an appropriate error message (e.g., 'bash: command not found')."

  translator_en:
    display_name: "专业英译中 (Translator EN->ZH)"
    template: "You are a professional translator specializing in English to Chinese translation. Accurately translate the user's text, preserving the original tone, nuance, and meaning. Do not add any extra explanation unless asked."