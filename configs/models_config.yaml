# 模型与指令配置文件
# 在这里定义你想要使用的所有模型
# api_key 可以直接写在这里，或者设置为 "ENV:YOUR_ENV_VARIABLE_NAME" 从环境变量读取

models:
  # 1. 本地 VLLM 部署的模型 (使用 OpenAI 兼容接口)
  qwen3-4b-local:
    provider: "openai_compatible"
    display_name: "Qwen3-4B-Instruct (本地)"
    api_base: "http://localhost:8000/v1"
    api_key: "not-used"
    
    model_name: "/home/lee/.cache/modelscope/hub/models/Qwen/Qwen3-4B-Instruct-2507" 
    
    parameters:
      temperature: 0.7
      max_tokens: 4096

  llama3-8b-vllm:
    provider: "openai_compatible"
    display_name: "Llama-3-8B (Local VLLM)"
    api_base: "http://localhost:8000/v1"
    api_key: "not-used"
    model_name: "meta-llama/Meta-Llama-3-8B-Instruct" 
    parameters:
      temperature: 0.7
      max_tokens: 4096

  # 2. 在线 OpenAI API 模型 (示例)
  # gpt-4o:
  #   provider: "openai_compatible"
  #   display_name: "GPT-4o (OpenAI API)"
  #   api_base: "https://api.openai.com/v1"
  #   api_key: "ENV:OPENAI_API_KEY" # 建议从环境变量读取
  #   model_name: "gpt-4o"
  #   parameters:
  #     temperature: 0.8
  #     max_tokens: 4096

  # 3. Groq API 模型 (示例, 同样兼容 OpenAI)
  # llama3-70b-groq:
  #   provider: "openai_compatible"
  #   display_name: "Llama-3-70B (Groq API)"
  #   api_base: "https://api.groq.com/openai/v1"
  #   api_key: "ENV:GROQ_API_KEY" # 从环境变量读取
  #   model_name: "llama3-70b-8192"
  #   parameters:
  #     temperature: 0.6
  #     max_tokens: 8192

  # 4. 本地 Hugging Face 模型 (未来扩展方向)
  # local_hf_model:
  #   provider: "huggingface_local"
  #   display_name: "My Local HF Model"
  #   # path 将与 app_config.yaml 中的 local_models_dir 拼接
  #   path: "path/to/your/model"
  #   parameters:
  #     temperature: 0.7
  #     max_tokens: 2048

# 指令库 (System Prompts)
# 在交互式聊天中通过 /instruction <指令名> 来使用
instructions:
  default: "You are a helpful AI assistant."
  code_expert: "You are an expert programmer. Provide clean, efficient, and well-documented code. Always explain your code with reasoning."
  translator: "You are a professional translator. Translate the user's text accurately and naturally, preserving the original tone and meaning."
  text_polisher: "As a writing expert, please polish the following text. Improve its clarity, grammar, and style, while keeping the core message intact."